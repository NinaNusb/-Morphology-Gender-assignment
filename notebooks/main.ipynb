{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file and load it as a DataFrame\n",
    "df = pd.read_json('../data/raw_scraped_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polish\n",
      "German\n",
      "French\n",
      "Spanish\n"
     ]
    }
   ],
   "source": [
    "# intial filtering of hypen, blank space, all digits and all caps words\n",
    "filtered = df[(~df['noun'].str.contains('-| |\\.|1|2|3|4|5|6|7|8|9|0')) & (~df['noun'].str.isupper())]\n",
    "x = filtered['lang'].unique()\n",
    "for y in x:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe into smaller ones by language\n",
    "def split_df(df: pd.DataFrame)-> List[Tuple[str, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Splits main df by 'lang' column, making 4\n",
    "    \"\"\"\n",
    "    languages = [lang for lang in df['lang'].unique()]\n",
    "    sub_dfs = [df[df['lang'] == lang] for lang in languages]\n",
    "    return [(lang, sub_df) for lang, sub_df in zip(languages, sub_dfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match sub dataFrames with its Spacy language model respectively\n",
    "def sub_df_and_model(df: pd.DataFrame)-> List[Tuple[pd.DataFrame, Language]]:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    sub_dfs = split_df(df) # list of all sub DataFrames based on language\n",
    "    d = {'Spanish': 'es', 'French': 'fr', 'German': 'de', 'Polish': 'pl'}\n",
    "    # list of tuples (language, spacy language model)\n",
    "    models = [(lang, spacy.load(lang + '_core_news_sm')) for lang in d.values()]\n",
    "    return [(sub_df[1], model[1]) for sub_df, model in zip(sub_dfs, models)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dfs(df: pd.DataFrame):\n",
    "    dfs_and_models = sub_df_and_model(df)\n",
    "    dfs = []\n",
    "    for tup in dfs_and_models: # fore every tuple (sub DataFrame, spacy model)\n",
    "        res = []\n",
    "        sub_df, nlp = tup # unpack tuple\n",
    "        words = pd.Series(sub_df['noun']).tolist() # list of all str values in 'noun'\n",
    "        for word in words: # for each word in list\n",
    "            doc = nlp(word) # create a doc via appropriate spacy model for a particular language\n",
    "            if doc[0].pos_ != 'PROPN': # since just one word is in doc, get its POS, if NOT a Proper Noun\n",
    "                res.append(word) # then append it to a list\n",
    "        dfs.append(sub_df[sub_df['noun'].isin(res)]) # create a new sub dataFrame IF 'noun' is in our list of non-proper nouns\n",
    "    return dfs # return the new list of sub dataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_to_json(sub_dfs: List[pd.DataFrame]):\n",
    "    for sub in sub_dfs:\n",
    "        lang = sub.iloc[0][2] # get value at first row, 3 column : Ex: Spanish, French, etc\n",
    "        sub.to_json('../data/' + lang + '_cleaned_data.json', orient='split')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
