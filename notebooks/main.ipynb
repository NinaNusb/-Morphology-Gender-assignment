{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (3.5.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (8.1.9)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (1.24.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (67.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages (from jinja2->spacy) (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../src/')\n",
    "from data_cleaning import raw_json_to_clean_df\n",
    "from data_transformation import transform, get_X_y, distribution\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K                                              0.0/12.8 MB 1.1 MB/s eta 0:00:12"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m spacy\u001b[39m.\u001b[39;49mcli\u001b[39m.\u001b[39;49mdownload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m spacy\u001b[39m.\u001b[39mcli\u001b[39m.\u001b[39mdownload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m spacy\u001b[39m.\u001b[39mcli\u001b[39m.\u001b[39mdownload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages/spacy/cli/download.py:75\u001b[0m, in \u001b[0;36mdownload\u001b[0;34m(model, direct, sdist, *pip_args)\u001b[0m\n\u001b[1;32m     71\u001b[0m     version \u001b[39m=\u001b[39m get_version(model_name, compatibility)\n\u001b[1;32m     73\u001b[0m filename \u001b[39m=\u001b[39m get_model_filename(model_name, version, sdist)\n\u001b[0;32m---> 75\u001b[0m download_model(filename, pip_args)\n\u001b[1;32m     76\u001b[0m msg\u001b[39m.\u001b[39mgood(\n\u001b[1;32m     77\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mDownload and installation successful\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mYou can now load the package via spacy.load(\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     79\u001b[0m )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages/spacy/cli/download.py:134\u001b[0m, in \u001b[0;36mdownload_model\u001b[0;34m(filename, user_pip_args)\u001b[0m\n\u001b[1;32m    132\u001b[0m pip_args \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(user_pip_args) \u001b[39mif\u001b[39;00m user_pip_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m []\n\u001b[1;32m    133\u001b[0m cmd \u001b[39m=\u001b[39m [sys\u001b[39m.\u001b[39mexecutable, \u001b[39m\"\u001b[39m\u001b[39m-m\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpip\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39minstall\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m pip_args \u001b[39m+\u001b[39m [download_url]\n\u001b[0;32m--> 134\u001b[0m run_command(cmd)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages/spacy/util.py:997\u001b[0m, in \u001b[0;36mrun_command\u001b[0;34m(command, stdin, capture)\u001b[0m\n\u001b[1;32m    995\u001b[0m     cmd_str \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(command)\n\u001b[1;32m    996\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 997\u001b[0m     ret \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m    998\u001b[0m         cmd_list,\n\u001b[1;32m    999\u001b[0m         env\u001b[39m=\u001b[39;49mos\u001b[39m.\u001b[39;49menviron\u001b[39m.\u001b[39;49mcopy(),\n\u001b[1;32m   1000\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mstdin,\n\u001b[1;32m   1001\u001b[0m         encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf8\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1002\u001b[0m         check\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1003\u001b[0m         stdout\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mPIPE \u001b[39mif\u001b[39;49;00m capture \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1004\u001b[0m         stderr\u001b[39m=\u001b[39;49msubprocess\u001b[39m.\u001b[39;49mSTDOUT \u001b[39mif\u001b[39;49;00m capture \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   1005\u001b[0m     )\n\u001b[1;32m   1006\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1007\u001b[0m     \u001b[39m# Indicates the *command* wasn't found, it's an error before the command\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     \u001b[39m# is run.\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         Errors\u001b[39m.\u001b[39mE970\u001b[39m.\u001b[39mformat(str_command\u001b[39m=\u001b[39mcmd_str, tool\u001b[39m=\u001b[39mcmd_list[\u001b[39m0\u001b[39m])\n\u001b[1;32m   1011\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[1;32m    502\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39;49mcommunicate(\u001b[39minput\u001b[39;49m, timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    504\u001b[0m     \u001b[39mexcept\u001b[39;00m TimeoutExpired \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    505\u001b[0m         process\u001b[39m.\u001b[39mkill()\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1144\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mread()\n\u001b[1;32m   1143\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 1144\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait()\n\u001b[1;32m   1145\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1146\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1207\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     endtime \u001b[39m=\u001b[39m _time() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m   1206\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1207\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1208\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1209\u001b[0m     \u001b[39m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1210\u001b[0m     \u001b[39m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m     \u001b[39m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m     \u001b[39m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1941\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1939\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturncode \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1940\u001b[0m     \u001b[39mbreak\u001b[39;00m  \u001b[39m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1941\u001b[0m (pid, sts) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_wait(\u001b[39m0\u001b[39;49m)\n\u001b[1;32m   1942\u001b[0m \u001b[39m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1943\u001b[0m \u001b[39m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1944\u001b[0m \u001b[39m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1945\u001b[0m \u001b[39mif\u001b[39;00m pid \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid:\n",
      "File \u001b[0;32m/usr/lib/python3.10/subprocess.py:1899\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1897\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1898\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1899\u001b[0m     (pid, sts) \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mwaitpid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpid, wait_flags)\n\u001b[1;32m   1900\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1901\u001b[0m     \u001b[39m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1902\u001b[0m     \u001b[39m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1903\u001b[0m     \u001b[39m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1904\u001b[0m     pid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.cli.download(\"de_core_web_sm\")\n",
    "spacy.cli.download(\"es_core_web_sm\")\n",
    "spacy.cli.download(\"fr_core_web_sm\")\n",
    "spacy.cli.download(\"pl_core_web_sm\")\n",
    "# nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection\n",
    "\n",
    "We begin by scrapping Wiktionary.org for *feminine*, *masculine*, and *neuter* nouns in *Polish*, *German*, *Spanish*, and *French*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run webscrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "The raw data in json format must be cleaned: removing nouns with *spaces*, *hyphens*, *numbers*, *abbreviations*, *initials* and finally those that are *proper nouns*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'es_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# read json file and load it as a DataFrame\u001b[39;00m\n\u001b[1;32m      2\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m../data/raw_scraped_data.json\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m raw_json_to_clean_df(path)\n",
      "File \u001b[0;32m~/Uni/S2/Ad Morpho/Project/-Morphology-Gender-assignment/notebooks/../src/data_cleaning.py:112\u001b[0m, in \u001b[0;36mraw_json_to_clean_df\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39mreads in raw data json file , applies filters, \u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39mand returns a final and clean df to be used on an NLP model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39m    pd.DataFrame\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    111\u001b[0m filtered_df \u001b[39m=\u001b[39m initial_filter(pd\u001b[39m.\u001b[39mread_json(path))\n\u001b[0;32m--> 112\u001b[0m \u001b[39mreturn\u001b[39;00m clean_df(filtered_df)\n",
      "File \u001b[0;32m~/Uni/S2/Ad Morpho/Project/-Morphology-Gender-assignment/notebooks/../src/data_cleaning.py:95\u001b[0m, in \u001b[0;36mclean_df\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39mtakes in a DataFrame, creates sub dataframes based on each unique language,\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[39mthen takes each word found in each sub dataframe and passes it into SpaCy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[39m    res(list): list of sub dataframes per language\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     94\u001b[0m Data \u001b[39m=\u001b[39m namedtuple(\u001b[39m'\u001b[39m\u001b[39mData\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mwords\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnlp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdf\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 95\u001b[0m df_and_nlp \u001b[39m=\u001b[39m sub_df_and_model(df)\n\u001b[1;32m     96\u001b[0m res \u001b[39m=\u001b[39m [] \n\u001b[1;32m     97\u001b[0m \u001b[39mfor\u001b[39;00m tup \u001b[39min\u001b[39;00m df_and_nlp:\n",
      "File \u001b[0;32m~/Uni/S2/Ad Morpho/Project/-Morphology-Gender-assignment/notebooks/../src/data_cleaning.py:59\u001b[0m, in \u001b[0;36msub_df_and_model\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     57\u001b[0m sub_dfs \u001b[39m=\u001b[39m df_lang(df) \n\u001b[1;32m     58\u001b[0m d \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mSpanish\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFrench\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mfr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGerman\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mde\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPolish\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mpl\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[0;32m---> 59\u001b[0m models \u001b[39m=\u001b[39m [Model(lang, spacy\u001b[39m.\u001b[39mload(lang \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_core_news_sm\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39mfor\u001b[39;00m lang \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mvalues()]\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m [Df_nlp(sub_df\u001b[39m.\u001b[39mdf, model\u001b[39m.\u001b[39mnlp) \u001b[39mfor\u001b[39;00m sub_df, model \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sub_dfs, models)]\n",
      "File \u001b[0;32m~/Uni/S2/Ad Morpho/Project/-Morphology-Gender-assignment/notebooks/../src/data_cleaning.py:59\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m sub_dfs \u001b[39m=\u001b[39m df_lang(df) \n\u001b[1;32m     58\u001b[0m d \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mSpanish\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFrench\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mfr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGerman\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mde\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPolish\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mpl\u001b[39m\u001b[39m'\u001b[39m}\n\u001b[0;32m---> 59\u001b[0m models \u001b[39m=\u001b[39m [Model(lang, spacy\u001b[39m.\u001b[39;49mload(lang \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_core_news_sm\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39mfor\u001b[39;00m lang \u001b[39min\u001b[39;00m d\u001b[39m.\u001b[39mvalues()]\n\u001b[1;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m [Df_nlp(sub_df\u001b[39m.\u001b[39mdf, model\u001b[39m.\u001b[39mnlp) \u001b[39mfor\u001b[39;00m sub_df, model \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sub_dfs, models)]\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages/spacy/__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     55\u001b[0m         name,\n\u001b[1;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     61\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages/spacy/util.py:449\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'es_core_news_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# read json file and load it as a DataFrame\n",
    "path = '../data/raw_scraped_data.json'\n",
    "df = raw_json_to_clean_df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>lemma</th>\n",
       "      <th>gender</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aalen</td>\n",
       "      <td>aalir</td>\n",
       "      <td>masculine</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abacysta</td>\n",
       "      <td>abacysta</td>\n",
       "      <td>masculine</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abatacept</td>\n",
       "      <td>abatacept</td>\n",
       "      <td>masculine</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abatacept</td>\n",
       "      <td>abatacept</td>\n",
       "      <td>masculine</td>\n",
       "      <td>French</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abatacept</td>\n",
       "      <td>abatacept</td>\n",
       "      <td>masculine</td>\n",
       "      <td>Polish</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        noun      lemma     gender    lang\n",
       "0      aalen      aalir  masculine  Polish\n",
       "1   abacysta   abacysta  masculine  Polish\n",
       "2  abatacept  abatacept  masculine  Polish\n",
       "3  abatacept  abatacept  masculine  French\n",
       "4  abatacept  abatacept  masculine  Polish"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Transform and Encode Data\n",
    "reduce data down to an even amount of examples per language and per gender\n",
    "encode last 3 letters of each noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capeta/Uni/S2/Ad Morpho/Project/-Morphology-Gender-assignment/notebooks/../src/data_transformation.py:15: FutureWarning: The default value of numeric_only in DataFrame.min is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  lowest = distribution(df).min()[0]\n",
      "/home/capeta/Uni/S2/Ad Morpho/Project/-Morphology-Gender-assignment/notebooks/../src/data_transformation.py:16: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  reduced_df = df.groupby(['lang', 'gender'])['noun', 'lemma', 'gender', 'lang'].sample(n=lowest)\n",
      "/home/capeta/.local/share/virtualenvs/-Morphology-Gender-assignment-lrLn6GZY/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>lemma</th>\n",
       "      <th>gender</th>\n",
       "      <th>lang</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>5848</th>\n",
       "      <th>5849</th>\n",
       "      <th>5850</th>\n",
       "      <th>5851</th>\n",
       "      <th>5852</th>\n",
       "      <th>5853</th>\n",
       "      <th>5854</th>\n",
       "      <th>5855</th>\n",
       "      <th>5856</th>\n",
       "      <th>5857</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>badauderie</td>\n",
       "      <td>Badauderie</td>\n",
       "      <td>feminine</td>\n",
       "      <td>French</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>féculerie</td>\n",
       "      <td>féculeria</td>\n",
       "      <td>feminine</td>\n",
       "      <td>French</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rando</td>\n",
       "      <td>rar</td>\n",
       "      <td>feminine</td>\n",
       "      <td>French</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>panthéiste</td>\n",
       "      <td>panthéiste</td>\n",
       "      <td>feminine</td>\n",
       "      <td>French</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tabagie</td>\n",
       "      <td>tabagi</td>\n",
       "      <td>feminine</td>\n",
       "      <td>French</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5862 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         noun       lemma    gender    lang    0    1    2    3    4    5  \\\n",
       "0  badauderie  Badauderie  feminine  French  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1   féculerie   féculeria  feminine  French  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2       rando         rar  feminine  French  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  panthéiste  panthéiste  feminine  French  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     tabagie      tabagi  feminine  French  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   ...  5848  5849  5850  5851  5852  5853  5854  5855  5856  5857  \n",
       "0  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4  ...   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 5862 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_df = transform(df)\n",
    "trans_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Train Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_X_y(trans_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Split data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8468354430379746"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8981012658227848"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Perceptron(random_state=42)\n",
    "p.fit(X_train, y_train)\n",
    "p.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
